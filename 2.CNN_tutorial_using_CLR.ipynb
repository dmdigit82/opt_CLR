{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import keras\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read data(CIFAR10)\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting hyperparameters\n",
    "img_row = 32\n",
    "img_col = 32\n",
    "img_ch = 3\n",
    "num_class = 10\n",
    "\n",
    "batch_size = 128\n",
    "baseLR = 0.0001\n",
    "maxLR = 0.0006\n",
    "num_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label data --> one-hot encoding\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train,num_class)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder('float32',shape=[None,img_row,img_col,img_ch],name=\"input\")\n",
    "Y = tf.placeholder('float32',shape=[None,num_class])\n",
    "lr = tf.placeholder('float32',shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(_input):\n",
    "    \n",
    "    #conv layer 1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        W = tf.get_variable('weight',[3,3,3,32],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[32],initializer=layers.xavier_initializer())\n",
    "        conv1 = tf.nn.conv2d(_input,W,strides=[1,1,1,1],padding='SAME')\n",
    "        conv1 = tf.nn.relu(conv1+b,name=scope.name)\n",
    "        print( conv1.shape)\n",
    "        \n",
    "    #conv layer2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        W = tf.get_variable('weight',[3,3,32,32],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[32],initializer=layers.xavier_initializer())\n",
    "        conv2 = tf.nn.conv2d(conv1,W,strides=[1,1,1,1],padding='SAME')\n",
    "        conv2 = tf.nn.relu(conv2+b)\n",
    "        conv2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        dr1 = tf.nn.dropout(conv2,keep_prob=0.25,name=scope.name)\n",
    "        print(dr1.shape)\n",
    "        \n",
    "    #conv layer3\n",
    "    with tf.variable_scope('conv3') as scope:\n",
    "        W = tf.get_variable('weight',[3,3,32,64],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[64],initializer=layers.xavier_initializer())\n",
    "        conv3 = tf.nn.conv2d(dr1,W,strides=[1,1,1,1],padding='SAME')\n",
    "        conv3 = tf.nn.relu(conv3+b)\n",
    "        print(conv3.shape)\n",
    "        \n",
    "    #conv layer4\n",
    "    with tf.variable_scope('conv4') as scope:\n",
    "        W = tf.get_variable('weight',[3,3,64,64],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[64],initializer=layers.xavier_initializer())\n",
    "        conv4 = tf.nn.conv2d(conv3,W,strides=[1,1,1,1],padding='SAME')\n",
    "        conv4 = tf.nn.relu(conv4+b)\n",
    "        conv4 = tf.nn.max_pool(conv4,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        dr2 = tf.nn.dropout(conv4,keep_prob=0.25,name=scope.name)\n",
    "        print(dr2.shape)\n",
    "        \n",
    "    #FC1\n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        dense = tf.reshape(dr2,[-1,4096])\n",
    "        print(dense.shape)\n",
    "        W = tf.get_variable('weight',[4096,512],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[512],initializer=layers.xavier_initializer())\n",
    "        \n",
    "        fc1 = tf.nn.relu(tf.matmul(dense,W)+b)\n",
    "        dr3 = tf.nn.dropout(fc1,keep_prob=0.5)\n",
    "        print(dr3.shape)\n",
    "   \n",
    "    #FC2\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        W = tf.get_variable('weight',[512,10],initializer=layers.xavier_initializer())\n",
    "        b = tf.get_variable('bias',[10],initializer=layers.xavier_initializer())\n",
    "        \n",
    "        fc2 = tf.nn.relu(tf.matmul(dr3,W)+b)\n",
    "        print(fc2.shape)\n",
    "        pred = fc2\n",
    "        \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 32)\n",
      "(?, 16, 16, 32)\n",
      "(?, 16, 16, 64)\n",
      "(?, 8, 8, 64)\n",
      "(?, 4096)\n",
      "(?, 512)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    pred = conv_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:1'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:2'):\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(loss)\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CLA_triangular(baseLR,iteration,stepsize):\n",
    "    cycle = math.floor(1+iteration/(2*stepsize))\n",
    "    x = math.fabs(iteration/stepsize - 2*cycle + 1)\n",
    "    baseLR = baseLR +(maxLR - baseLR)*max(0,(1-x))\n",
    "    return baseLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting tensorflow config\n",
    "config = tf.ConfigProto(allow_soft_placement=True,log_device_placement=True,device_count = {'GPU': 1})\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization(X_train,Y_train,X_valid,Y_valid,model_dir,patience=-1):\n",
    "    \n",
    "    check_point = 0\n",
    "    best_validation_accuracy = 0.0\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(num_epoch),desc=\"epoch\"):\n",
    "        total_batch = int(np.shape(X_train)[0]/batch_size)\n",
    "        \n",
    "        #data shuffling\n",
    "        X_train_copy = np.copy(X_train)\n",
    "        Y_train_copy = np.copy(Y_train)\n",
    "        \n",
    "        train_index = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(train_index)\n",
    "        \n",
    "        X_train_copy = X_train_copy[train_index]\n",
    "        Y_train_copy = Y_train_copy[train_index]\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            batch_x = X_train_copy[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = Y_train_copy[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            iterator_size = (epoch)*X_train.shape[0]+(i+1)\n",
    "            batch_lr = CLA_triangular(baseLR,iterator_size,total_batch/2)\n",
    "            \n",
    "            feed_dict_train = {X:batch_x, Y:batch_y, lr:batch_lr}\n",
    "            \n",
    "            sess.run(optimizer,feed_dict=feed_dict_train)\n",
    "            \n",
    "            acc_train = sess.run(accuracy,feed_dict=feed_dict_train)\n",
    "            \n",
    "            sys.stdout.write(\"\\r%0.3f\"%acc_train)\n",
    "            \n",
    "            if((i+1) % total_batch ==0):\n",
    "                acc_train = sess.run(accuracy,feed_dict=feed_dict_train)\n",
    "                acc_valid = sess.run(accuracy,feed_dict={X:X_valid,Y:Y_valid,lr:batch_lr})\n",
    "                \n",
    "                if(best_validation_accuracy < acc_valid):\n",
    "                    best_validation_accuracy = acc_valid\n",
    "                    \n",
    "                    improved_str = '*'\n",
    "                    checkpoint = 0\n",
    "                    saver.save(sess,model_dir)\n",
    "                \n",
    "                else:\n",
    "                    improved_str = ''\n",
    "                    checkpoint +=1\n",
    "                \n",
    "                msg = \"epoch: {0:>6}, Train-Batch Accuracy: {1:6.1%}, Validation Accuracy: {2:6.1%} {3} \"\n",
    "                print(msg.format(epoch+1,acc_train,acc_valid,improved_str))\n",
    "        if(checkpoint ==patience):\n",
    "            print(\"No improvement found. Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3638e82e5724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model/2.CNN_tutorial_bst_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-8a5e86e6a574>\u001b[0m in \u001b[0;36moptimization\u001b[0;34m(X_train, Y_train, X_valid, Y_valid, model_dir, patience)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mfeed_dict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shjung/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shjung/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shjung/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/shjung/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shjung/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    optimization(x_train,y_train,x_test,y_test,\"model/2.CNN_tutorial_bst_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "485d1da4ce6d405a9dd69a1cfd1d7e9b": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
